{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# if need be, manually add the local project root to PYTHONPATH and move working directories\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project = '/' # change to local project root\n",
    "sys.path.append(project)\n",
    "os.chdir(project)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# dependencies\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pystan as stan\n",
    "\n",
    "import nfx.lm.gibbs\n",
    "import nfx.misc.plot"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# helper functions\n",
    "\n",
    "def package_sla_samples(samples, node_names, covariate_names):\n",
    "\n",
    "    coef_samples, prec_samples, nuisance_samples = zip(*sla_samples)\n",
    "    coef_samples = [np.array(coef_samples_) for coef_samples_ in zip(*coef_samples)][::-1]\n",
    "    prec_samples = np.trace(prec_samples, axis1=2, axis2=3).T[::-1]\n",
    "    nuisance_samples = np.array(nuisance_samples).T\n",
    "    return package_coef_samples(coef_samples, node_names, covariate_names, 'SLA'), package_prec_samples(prec_samples, 'SLA'), package_nuisance_samples(nuisance_samples, node_names[-1], 'SLA')\n",
    "\n",
    "def package_nuts_samples(samples, node_names, covariate_names):\n",
    "\n",
    "    coef_samples = [s[:, 0] for s in [samples[par] for par in ('loc_0', 'loc_1', 'loc_2', 'loc_3', 'coefs')]]\n",
    "    coef_samples[0] = coef_samples[0][:, np.newaxis]\n",
    "    prec_samples = np.array([[np.trace(np.linalg.inv(tau__[0])) for tau__ in tau_] for tau_ in [nuts_samples[par] for par in ('cov_1', 'cov_2', 'cov_3', 'cov_4')]])\n",
    "    nuisance_samples = 1 / samples['var_resid'][:, 0].T\n",
    "    return package_coef_samples(coef_samples, node_names, covariate_names, 'Stan/NUTS'), package_prec_samples(prec_samples, 'Stan/NUTS'), package_nuisance_samples(nuisance_samples, node_names[-1], 'Stan/NUTS')\n",
    "\n",
    "def package_coef_samples(coef_samples, node_names, covariate_names, algo_name):\n",
    "\n",
    "    dfs = []\n",
    "    for i, (coef_samples_, node_names_) in enumerate(zip(coef_samples, node_names)):\n",
    "        for j, node_names__ in enumerate(node_names_):\n",
    "            df_ = pd.DataFrame(coef_samples_[:, j].T, index=covariate_names)\n",
    "            df_.index = df_.index.rename('covariate')\n",
    "            df_.columns = df_.columns.rename('iter')\n",
    "            df_['algo'] = algo_name\n",
    "            df_['level'] = i\n",
    "            df_['node'] = node_names__.zfill(i + 1)\n",
    "            dfs.append(df_)\n",
    "    df = pd.concat(dfs).reset_index().set_index(['algo', 'level', 'node', 'covariate'])\n",
    "    return df\n",
    "\n",
    "def package_prec_samples(prec_samples, algo_name):\n",
    "\n",
    "    df = pd.DataFrame(prec_samples, index=np.arange(len(prec_samples)))\n",
    "    df.index = df.index.rename('level')\n",
    "    df.columns = df.columns.rename('iter')\n",
    "    df['algo'] = algo_name\n",
    "    df = df.reset_index().set_index(['algo', 'level'])\n",
    "    return df\n",
    "\n",
    "def package_nuisance_samples(nuisance_samples, node_names, algo_name):\n",
    "\n",
    "    df = pd.DataFrame(np.mean(nuisance_samples, 0)[np.newaxis], index=['mean'])\n",
    "    df.index = df.index.rename('node')\n",
    "    df.columns = df.columns.rename('iter')\n",
    "    df['algo'] = algo_name\n",
    "    df = df.reset_index().set_index(['algo', 'node'])\n",
    "    return df\n",
    "        \n",
    "def est_acf(samples, n_lags):\n",
    "\n",
    "    acf = samples.apply(lambda x: nfx.misc.plot.est_acf(x.values, n_lags), 1, False, 'expand')\n",
    "    acf.columns = acf.columns.rename('lag')\n",
    "    return acf\n",
    "\n",
    "def est_ess(acfs, titer):\n",
    "    \n",
    "    df = pd.DataFrame(index=acfs.index)\n",
    "    df['iat[iter]'] = acfs.apply(lambda x: nfx.misc.plot.est_int_autocor(x.values), 1, False, 'expand').rename('iat')\n",
    "    df['iat[sec]'] = df['iat[iter]'] * titer\n",
    "    df['rate[iter]'] = 1 / (2 * df['iat[iter]'])\n",
    "    df['rate[sec]'] = df['rate[iter]'] / titer\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# config\n",
    "\n",
    "covariate_names = ['housing']\n",
    "seed = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load data\n",
    "\n",
    "macro = pd.read_csv('paper/data/sareb_covariates.csv').set_index('time')\n",
    "prices = pd.read_csv('paper/data/sareb_prices_synthetic.csv').set_index('zip')\n",
    "rng = np.random.default_rng(seed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# format response\n",
    "\n",
    "response = prices.diff(axis=1).dropna(axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# format covariates\n",
    "\n",
    "covariates = macro.loc[:, covariate_names]\n",
    "covariates['_constant'] = 1\n",
    "covariates['_trend'] = np.arange(covariates.shape[0])\n",
    "covariates = covariates.loc[:, ['_trend', 'housing']].diff().dropna().loc[response.columns]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# construct tree\n",
    "\n",
    "indices = response.index.to_frame()\n",
    "indices['lvl_1'] = indices.zip.str.slice(0, 2)\n",
    "indices['lvl_2'] = indices.zip.str.slice(0, 3)\n",
    "indices['lvl_3'] = indices.zip.str.slice(0, 4)\n",
    "indices['lvl_4'] = indices.zip.str.slice(0, 5)\n",
    "indices = indices.drop('zip', 1)\n",
    "codes = indices.apply(lambda x: x.astype('category').cat.codes).astype('int64')\n",
    "n_nodes = codes.max(0) + 1\n",
    "parent_node_3 = codes[['lvl_4', 'lvl_3']].drop_duplicates().lvl_3\n",
    "parent_node_2 = codes[['lvl_3', 'lvl_2']].drop_duplicates().lvl_2\n",
    "parent_node_1 = codes[['lvl_2', 'lvl_1']].drop_duplicates().lvl_1\n",
    "tree = [parent_node_3, parent_node_2, parent_node_1]\n",
    "node_names = [['0'], indices.lvl_1.unique(), indices.lvl_2.unique(), indices.lvl_3.unique(), indices.lvl_4.unique()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# assemble nuts inputs\n",
    "\n",
    "nuts_inputs = {\n",
    "    'n_periods': response.shape[1],\n",
    "    'n_leaves': response.shape[0],\n",
    "    'n_covariates': covariates.shape[1],\n",
    "    'n_nodes_3': parent_node_3.max() + 1,\n",
    "    'n_nodes_2': parent_node_2.max() + 1,\n",
    "    'n_nodes_1': parent_node_1.max() + 1,\n",
    "    'parent_node_3': parent_node_3.values + 1,\n",
    "    'parent_node_2': parent_node_2.values + 1,\n",
    "    'parent_node_1': parent_node_1.values + 1,\n",
    "    'covariates': covariates.values.T,\n",
    "    'response': response.values,\n",
    "    'prior_df': covariates.shape[1],\n",
    "    'prior_shape': 1/2,\n",
    "    'prior_rate': 1/2\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sample nuts\n",
    "\n",
    "nuts_n_samples = 1000\n",
    "stan_model = stan.StanModel('paper/stan/nfx_panel_normal.stan')\n",
    "t0 = datetime.datetime.now()\n",
    "stan_sampler = stan_model.sampling(data=nuts_inputs, iter=2*nuts_n_samples, warmup=nuts_n_samples, chains=1, seed=0)\n",
    "t1 = datetime.datetime.now()\n",
    "nuts_titer = (t1 - t0).total_seconds() / nuts_n_samples\n",
    "nuts_leaps = stan_sampler.get_sampler_params(inc_warmup=False)[0]['n_leapfrog__'].mean()\n",
    "nuts_samples = stan_sampler.extract(['loc_0', 'loc_1', 'loc_2', 'loc_3', 'coefs', 'cov_1', 'cov_2', 'cov_3', 'cov_4', 'var_resid'], permuted=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# nuts iteration time\n",
    "\n",
    "print(nuts_titer, nuts_leaps)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# compute nuts summaries\n",
    "\n",
    "nuts_coef_samples, nuts_prec_samples, nuts_nuisance_samples = package_nuts_samples(nuts_samples, node_names, ['_trend'] + covariate_names)\n",
    "nuts_coef_acf, nuts_prec_acf, nuts_nuisance_acf = (est_acf(samples_, 64) for samples_ in (nuts_coef_samples, nuts_prec_samples, nuts_nuisance_samples))\n",
    "nuts_coef_ess, nuts_prec_ess, nuts_nuisance_ess = (est_ess(acfs_, nuts_titer) for acfs_ in (nuts_coef_acf, nuts_prec_acf, nuts_nuisance_acf))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# construct sla inputs\n",
    "\n",
    "sla_inputs = (response.values, covariates.values, tree)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sample sla. stop at 2000 iterations to save memory\n",
    "\n",
    "sla_n_samples = 2000\n",
    "sla_sampler = nfx.lm.gibbs.sample_posterior(*sla_inputs, ome=rng)\n",
    "next(sla_sampler)\n",
    "t0 = datetime.datetime.now()\n",
    "sla_samples = [next(sla_sampler) for _ in  range(10 + sla_n_samples)][10:]\n",
    "t1 = datetime.datetime.now()\n",
    "sla_titer = (t1 - t0).total_seconds() / sla_n_samples"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sla iteration time\n",
    "\n",
    "print(sla_titer)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# compute sla summaries\n",
    "\n",
    "sla_coef_samples, sla_prec_samples, sla_nuisance_samples = package_sla_samples(sla_samples, node_names, ['_trend'] + covariate_names)\n",
    "sla_coef_acf, sla_prec_acf, sla_nuisance_acf = (est_acf(samples_, 256) for samples_ in (sla_coef_samples, sla_prec_samples, sla_nuisance_samples))\n",
    "sla_coef_ess, sla_prec_ess, sla_nuisance_ess = (est_ess(acfs_, sla_titer) for acfs_ in (sla_coef_acf, sla_prec_acf, sla_nuisance_acf))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# stack\n",
    "\n",
    "coef_acf = pd.concat([sla_coef_acf, nuts_coef_acf])\n",
    "prec_acf = pd.concat([sla_prec_acf, nuts_prec_acf])\n",
    "nuisance_acf = pd.concat([sla_nuisance_acf, nuts_nuisance_acf])\n",
    "coef_ess = pd.concat([sla_coef_ess, nuts_coef_ess])\n",
    "prec_ess = pd.concat([sla_prec_ess, nuts_prec_ess])\n",
    "nuisance_ess = pd.concat([sla_nuisance_ess, nuts_nuisance_ess])"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd00414ad82ab456811b10c2eaad0962924c5698674072e97130a475dec6a2d3b36",
   "display_name": "Python 3.8.5 64-bit ('nfx_remote-j07VlOPI': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "0414ad82ab456811b10c2eaad0962924c5698674072e97130a475dec6a2d3b36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}